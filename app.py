import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import base64
import re
import streamlit.components.v1 as components

st.set_page_config(page_title="ì—…ë¬´ì¼ì§€ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# âœ… ë¡œê³  base64 ì¸ì½”ë”©í•´ì„œ ì„¸ì…˜ì— ì €ì¥
@st.cache_data
def load_logo_base64(path='ë¡œê³ .jpg'):
    with open(path, "rb") as image_file:
        encoded = base64.b64encode(image_file.read()).decode()
        return encoded

if 'logo_base64' not in st.session_state:
    try:
        st.session_state['logo_base64'] = load_logo_base64("ë¡œê³ .jpg")
    except FileNotFoundError:
        st.session_state['logo_base64'] = ""


def split_workers(worker_string):
    worker_string = re.sub(r'[.,\s]', ',', str(worker_string))  # ì‰¼í‘œ, ë§ˆì¹¨í‘œ, ê³µë°± â†’ ì‰¼í‘œ
    worker_string = re.sub(r'(?<=[ê°€-í£]{2})(?=[ê°€-í£]{2})', ',', worker_string)  # ë¶™ì—¬ì“°ê¸°ëœ í•œê¸€ ì´ë¦„ ë¶„ë¦¬
    return [name.strip() for name in worker_string.split(',') if name.strip()]


def process_data(uploaded_file):
    df_original = pd.read_csv(uploaded_file)
    df = df_original.copy()
    df['ì›ë³¸ì‘ì—…ì'] = df['ì‘ì—…ì']
    df['ì‹œì‘ì¼ì‹œ'] = pd.to_datetime(df['ì‹œì‘ì¼ì‹œ'])
    df['ì¢…ë£Œì¼ì‹œ'] = pd.to_datetime(df['ì¢…ë£Œì¼ì‹œ'])
    df['ì‘ì—…ì‹œê°„(ë¶„)'] = (df['ì¢…ë£Œì¼ì‹œ'] - df['ì‹œì‘ì¼ì‹œ']).dt.total_seconds() / 60
    # âœ… ë™ì¼ ì‘ì—…ì + ë™ì¼ ì‹œê°„ëŒ€ ì¤‘ë³µ ì œê±°
    df = df.drop_duplicates(subset=['ì‘ì—…ì', 'ì‹œì‘ì¼ì‹œ', 'ì¢…ë£Œì¼ì‹œ'])
    df['ì‘ì—…ìëª©ë¡'] = df['ì‘ì—…ì'].apply(split_workers)
    df['ì¡°êµ¬ì„±'] = df['ì‘ì—…ìëª©ë¡'].apply(lambda x: '2ì¸ 1ì¡°' if len(x) >= 2 else '1ì¸ 1ì¡°')
    df = df.explode('ì‘ì—…ìëª©ë¡')
    df['ì‘ì—…ì'] = df['ì‘ì—…ìëª©ë¡'].astype(str).str.strip()
    df.drop(columns=['ì‘ì—…ìëª©ë¡'], inplace=True)
    df['ì£¼ì°¨'] = df['ì‹œì‘ì¼ì‹œ'].apply(lambda x: f"{x.month}ì›”{x.day // 7 + 1}ì£¼")
    df['ì‘ì—…ì¼'] = pd.to_datetime(df['ì‹œì‘ì¼ì‹œ'].dt.date)
    return df, df_original


def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8-sig')


# âœ… HSL â†’ HEX ë³€í™˜ ìœ í‹¸ (matplotlib ì œê±°ìš©)
def hsl_to_hex(h, s, l):
    c = (1 - abs(2*l - 1)) * s
    x = c * (1 - abs((h/60) % 2 - 1))
    m = l - c/2
    if   0 <= h < 60:   r1, g1, b1 = c, x, 0
    elif 60 <= h < 120: r1, g1, b1 = x, c, 0
    elif 120 <= h < 180:r1, g1, b1 = 0, c, x
    elif 180 <= h < 240:r1, g1, b1 = 0, x, c
    elif 240 <= h < 300:r1, g1, b1 = x, 0, c
    else:               r1, g1, b1 = c, 0, x
    r, g, b = int((r1 + m) * 255), int((g1 + m) * 255), int((b1 + m) * 255)
    return f'#{r:02x}{g:02x}{b:02x}'


def main():
    col1, col2 = st.columns([8, 1])
    with col1:
        st.markdown("""
<h1 style='font-size: 50px;'>ğŸ“Š  <span style='color:#d32f2f;'>MOS</span>tagram ë¶„ì„ ëŒ€ì‹œë³´ë“œ</h1>
""", unsafe_allow_html=True)
    with col2:
        logo_base64 = st.session_state.get('logo_base64', "")
        st.markdown(f"""
        <div style='display: flex; justify-content: flex-end;'>
            <img src='data:image/jpeg;base64,{logo_base64}' width='180'>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("""
<p style='font-size: 25px;'>ì—…ë¬´ì¼ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³ , íŒ€ê³¼ íŒ€ì›ë³„ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.</p>
""", unsafe_allow_html=True)

    uploaded_file = st.file_uploader("ğŸ“ work_report.csv íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
    st.markdown("""
<div style='padding: 12px; background-color: #f0f8ff; border-left: 5px solid #0072C6; font-weight: bold; font-size: 16px;'>
ğŸ“¤ MOStagram ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ì—…ë¡œë“œí•˜ë©´ ëŒ€ì‹œë³´ë“œê°€ í‘œì‹œë©ë‹ˆë‹¤.
</div>
""", unsafe_allow_html=True)

    if uploaded_file:
        # âœ… ì»¬ëŸ¼ ì¡´ì¬ ê²€ì¦(ì—…ë¡œë“œ ì§í›„)
        cols_df = pd.read_csv(uploaded_file, nrows=0)
        required_cols = ['íŒ€','ì‘ì—…ì','ì‹œì‘ì¼ì‹œ','ì¢…ë£Œì¼ì‹œ','ì—…ë¬´ì¢…ë¥˜','êµ¬ë¶„','ì¥ë¹„ID','ì¥ë¹„ëª…']
        missing = [c for c in required_cols if c not in cols_df.columns]
        if missing:
            st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing} â€” CSV ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        uploaded_file.seek(0)

        # âœ… ë°ì´í„° ê°€ê³µ
        df, _ = process_data(uploaded_file)

        with st.sidebar:
            st.header("ğŸ” ê²€ìƒ‰")
            min_date = df['ì‹œì‘ì¼ì‹œ'].min().date()
            max_date = df['ì¢…ë£Œì¼ì‹œ'].max().date()
            start_date, end_date = st.date_input("ì‘ì—… ê¸°ê°„ í•„í„°", [min_date, max_date], min_value=min_date, max_value=max_date)

        df = df[(df['ì‹œì‘ì¼ì‹œ'].dt.date >= start_date) & (df['ì¢…ë£Œì¼ì‹œ'].dt.date <= end_date)]

        if 'íŒ€' in df.columns:
            team_options = df['íŒ€'].dropna().unique().tolist()
            selected_team = st.sidebar.selectbox("íŒ€ ì„ íƒ", ["ì „ì²´"] + team_options)
            if selected_team != "ì „ì²´":
                df = df[df['íŒ€'] == selected_team]

            member_options = (
                df['ì‘ì—…ì']
                  .astype(str).str.strip()
                  .replace({'nan': ''})
                  .replace('', np.nan)
                  .dropna()
                  .unique().tolist()
            )
            with st.sidebar.expander("**ì‘ì—…ì ì„ íƒ**", expanded=False):
                selected_members = st.multiselect(
                    "ì‘ì—…ì ëª©ë¡",
                    options=member_options,
                    default=member_options
                )
            df = df[df['ì‘ì—…ì'].isin(selected_members)]
        # ë°ì´í„° ì—†ìŒ ë°©ì§€
        if df.empty:
            st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
            st.stop()

        # âœ… ì‚¬ì´ë“œë°” í•˜ë‹¨ì— CSV ì €ì¥ ë²„íŠ¼
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ’¾ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        csv = convert_df_to_csv(df)
        st.sidebar.download_button(
            label="ğŸ“¥ CSV íŒŒì¼ ì €ì¥",
            data=csv,
            file_name="ì—…ë¬´ì¼ì§€_ë¶„ì„ê²°ê³¼.csv",
            mime="text/csv"
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # âœ… ì¤‘ë³µ ì¶œë™ í˜„í™©  (ë¨¼ì € í‘œì‹œ)
        st.markdown("## ğŸ” ì¤‘ë³µ ì¶œë™ í˜„í™©")
        dup_equipment = df[
            (df['ì—…ë¬´ì¢…ë¥˜'] == 'ë¬´ì„ ') &
            (df['êµ¬ë¶„'] == 'ì¥ì• /ì•ŒëŒ(AS)') &
            df['ì¥ë¹„ID'].notna() &
            (df['ì¥ë¹„ID'].astype(str).str.strip() != '') &
            df['ì¥ë¹„ëª…'].notna() &
            (df['ì¥ë¹„ëª…'].astype(str).str.strip() != '') &
            (~df['ì¥ë¹„ëª…'].astype(str).str.contains('ë¯¼ì›', regex=False)) &
            (~df['ì¥ë¹„ëª…'].astype(str).str.contains('ì‚¬ë¬´', regex=False))
        ]

        duplicated_ids = dup_equipment['ì¥ë¹„ID'].value_counts()
        duplicated_ids = duplicated_ids[duplicated_ids >= 3].index
        dup_equipment = dup_equipment[dup_equipment['ì¥ë¹„ID'].isin(duplicated_ids)]

        grouped = dup_equipment.groupby(['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID', 'ì‘ì—…ì']).size().reset_index(name='ê±´ìˆ˜')
        grouped['ì‘ì—…ì'] = grouped['ì‘ì—…ì'] + '(' + grouped['ê±´ìˆ˜'].astype(str) + ')'
        grouped.rename(columns={'ì‘ì—…ì': 'ì‘ì—…ì(ì¶œë™ íšŸìˆ˜)'}, inplace=True)
        grouped = grouped.sort_values(by=['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID', 'ê±´ìˆ˜'], ascending=[True, True, True, False])
        combined = grouped.groupby(['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID'])['ì‘ì—…ì(ì¶œë™ íšŸìˆ˜)'].apply(lambda x: ', '.join(x)).reset_index()

        ì¤‘ë³µê±´ìˆ˜_df = dup_equipment.drop_duplicates(subset=['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID', 'ì‹œì‘ì¼ì‹œ', 'ì¢…ë£Œì¼ì‹œ'])
        ì¤‘ë³µê±´ìˆ˜_df = ì¤‘ë³µê±´ìˆ˜_df.groupby(['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID']).size().reset_index(name='ì¤‘ë³µê±´ìˆ˜')

        combined = combined.merge(ì¤‘ë³µê±´ìˆ˜_df, on=['íŒ€', 'ì¥ë¹„ëª…', 'ì¥ë¹„ID'], how='left')
        combined = combined[combined['ì¤‘ë³µê±´ìˆ˜'] >= 3]
        dup_equipment_sorted = combined.sort_values(by='ì¤‘ë³µê±´ìˆ˜', ascending=False).reset_index(drop=True)
        st.dataframe(dup_equipment_sorted.rename(columns={'íŒ€': 'ìš´ìš©íŒ€'}), use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ‘¤ ê°œì¸ë³„ ëˆ„ë½ í˜„í™©  (ë‹¤ìŒ í‘œì‹œ)
        # âœ… ì‘ì—…ì ë¶„ë¦¬ ê¸°ì¤€ ì¶”ê°€
        split_df = df.copy()
        split_df['ì‘ì—…ì'] = split_df['ì‘ì—…ì'].astype(str)
        split_df['ì‘ì—…ì'] = split_df['ì‘ì—…ì'].str.replace('.', ',', regex=False).str.replace(' ', ',', regex=False).str.split(',')
        split_df = split_df.explode('ì‘ì—…ì')
        split_df['ì‘ì—…ì'] = split_df['ì‘ì—…ì'].str.strip()

        all_workers = split_df.groupby('ì‘ì—…ì')['íŒ€'].first().reset_index()
        date_range = pd.date_range(start=df['ì‘ì—…ì¼'].min(), end=df['ì‘ì—…ì¼'].max(), freq='B')
        all_worker_days = pd.MultiIndex.from_product([all_workers['ì‘ì—…ì'], date_range], names=['ì‘ì—…ì', 'ì‘ì—…ì¼'])
        all_worker_days = pd.DataFrame(index=all_worker_days).reset_index().merge(all_workers, on='ì‘ì—…ì')

        # âœ… "ê°œì¸ë³„ ì—…ë¬´ì¼ì§€ ëˆ„ë½ í˜„í™©" ê³„ì‚°ìš©: ì‘ì—…ì 2ëª… ì´ìƒ ë¶„ë¦¬ (ì¤‘ë³µ ì œê±° ë²„ì „)
        df_nul = df.copy()
        df_nul['ì‘ì—…ì'] = df_nul['ì‘ì—…ì'].astype(str).str.replace('.', ',', regex=False).str.replace(' ', ',', regex=False)
        df_nul['ì‘ì—…ì'] = df_nul['ì‘ì—…ì'].str.split(',')
        df_nul = df_nul.explode('ì‘ì—…ì')
        df_nul['ì‘ì—…ì'] = df_nul['ì‘ì—…ì'].str.strip()

        actual_logs = df_nul.groupby(['íŒ€', 'ì‘ì—…ì', 'ì‘ì—…ì¼']).size()
        log_df = all_worker_days.merge(
            actual_logs.rename('ì‘ì„±ì—¬ë¶€').reset_index(),
            on=['íŒ€', 'ì‘ì—…ì', 'ì‘ì—…ì¼'],
            how='left'
        ).fillna({'ì‘ì„±ì—¬ë¶€': 0})

        # âœ… í•˜ë£¨ì— ì—¬ëŸ¬ ê±´ì´ ìˆì–´ë„ ì‘ì„±ì—¬ë¶€ëŠ” 1ë¡œ ì²˜ë¦¬(ëˆ„ë½ë¥  ì™œê³¡ ë°©ì§€)
        log_df['ì‘ì„±ì—¬ë¶€'] = (log_df['ì‘ì„±ì—¬ë¶€'] > 0).astype(int)

        st.markdown("## ğŸ“‹ ê°œì¸ë³„ ëˆ„ë½ í˜„í™©")
        personal_summary = log_df.groupby(['íŒ€', 'ì‘ì—…ì'])['ì‘ì„±ì—¬ë¶€'].agg(['mean', 'count']).reset_index()
        personal_summary = personal_summary[personal_summary['mean'] < 1.0].copy()
        personal_summary['ëˆ„ë½ì¼ìˆ˜'] = (1 - personal_summary['mean']) * personal_summary['count']
        personal_summary['ëˆ„ë½ë¥ (%)'] = (1 - personal_summary['mean']) * 100

        personal_summary = personal_summary.sort_values('ëˆ„ë½ì¼ìˆ˜', ascending=False).head(30)
        personal_summary.reset_index(drop=True, inplace=True)
        styled_df = personal_summary[['íŒ€', 'ì‘ì—…ì', 'ëˆ„ë½ì¼ìˆ˜', 'ëˆ„ë½ë¥ (%)']]
        styled_df['ëˆ„ë½ì¼ìˆ˜'] = styled_df['ëˆ„ë½ì¼ìˆ˜'].astype(int)
        styled_df['ëˆ„ë½ë¥ (%)'] = styled_df['ëˆ„ë½ë¥ (%)'].astype(int)

        # âœ” ê°œì¸ë³„ ëˆ„ë½ í˜„í™© â€” í‘œ í˜•ì‹(ì¤‘ë³µ ì¶œë™ í˜„í™©ê³¼ ë™ì¼ ìŠ¤íƒ€ì¼)
        table_df = (
            styled_df
            .sort_values(by=['ëˆ„ë½ì¼ìˆ˜', 'ëˆ„ë½ë¥ (%)'], ascending=[False, False])
            .reset_index(drop=True)
            .rename(columns={'íŒ€': 'ìš´ìš©íŒ€'})
        )
        st.dataframe(table_df, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ•’ êµ¬ë¶„ë³„ MTTR / ë°˜ë³µë„ (ì´ ì„¹ì…˜ë§Œ ì´ë™ì—…ë¬´ ì œì™¸)
        st.markdown("## ğŸ•’ êµ¬ë¶„ë³„ MTTR / ë°˜ë³µë„")

        _mttr_keys = ['íŒ€', 'ì›ë³¸ì‘ì—…ì', 'ì‹œì‘ì¼ì‹œ', 'ì¢…ë£Œì¼ì‹œ', 'êµ¬ë¶„', 'ì¥ë¹„ID']
        mttr_df = df.drop_duplicates(subset=_mttr_keys).copy()

        # ì¥ë¹„ID ì •ë¦¬ ë° ìŒìˆ˜ ì‘ì—…ì‹œê°„ ì œê±°
        mttr_df['ì¥ë¹„ID'] = mttr_df['ì¥ë¹„ID'].astype(str).str.strip()
        mttr_df = mttr_df[mttr_df['ì‘ì—…ì‹œê°„(ë¶„)'] >= 0]

        # âœ… 'ì‚¬ë¬´ì—…ë¬´' ì œì™¸
        mttr_df = mttr_df[mttr_df['êµ¬ë¶„'].astype(str).str.strip() != 'ì‚¬ë¬´ì—…ë¬´']

        # âœ… 'ì´ë™ì—…ë¬´' ì œì™¸ (ìš”ì²­ ì„¹ì…˜ í•œì •)
        mttr_df = mttr_df[mttr_df['ì—…ë¬´ì¢…ë¥˜'].astype(str).str.strip() != 'ì´ë™ì—…ë¬´']

        if mttr_df.empty:
            st.info("ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„í„° ì¡°ê±´ì„ í™•ì¸í•´ ì£¼ì„¸ìš”)")
        else:
            def _p90(x):
                try:
                    return float(np.percentile(x, 90))
                except Exception:
                    return float(np.nan)

            mttr_tbl = (
                mttr_df
                .groupby('êµ¬ë¶„', dropna=False)['ì‘ì—…ì‹œê°„(ë¶„)']
                .agg(ê±´ìˆ˜='count', MTTR_ë¶„='mean', ì¤‘ì•™ê°’_ë¶„='median', P90_ë¶„=_p90)
                .reset_index()
            )

            rep_src = (
                mttr_df
                .loc[mttr_df['ì¥ë¹„ID'].notna() & (mttr_df['ì¥ë¹„ID'] != '')]
                .groupby(['êµ¬ë¶„', 'ì¥ë¹„ID']).size().reset_index(name='ê±´ìˆ˜')
            )
            rep_sum = rep_src.groupby('êµ¬ë¶„')['ì¥ë¹„ID'].nunique().reset_index(name='ê³ ìœ ì¥ë¹„ìˆ˜')
            rep_cnt = rep_src[rep_src['ê±´ìˆ˜'] >= 2].groupby('êµ¬ë¶„')['ì¥ë¹„ID'].nunique().reset_index(name='ì¬ë°œì¥ë¹„ìˆ˜')
            rep_tbl = rep_sum.merge(rep_cnt, on='êµ¬ë¶„', how='left').fillna({'ì¬ë°œì¥ë¹„ìˆ˜': 0})
            rep_tbl['ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)'] = (
                (rep_tbl['ì¬ë°œì¥ë¹„ìˆ˜'] / rep_tbl['ê³ ìœ ì¥ë¹„ìˆ˜']).replace([np.inf, np.nan], 0) * 100
            )

            result = mttr_tbl.merge(rep_tbl, on='êµ¬ë¶„', how='left')

            # âœ… ì •ìˆ˜ í‘œê¸°(ë¶„/ê°œìˆ˜/ë¹„ìœ¨)
            result['MTTR(ë¶„)'] = result['MTTR_ë¶„'].round().astype('Int64')
            result['ì¤‘ì•™ê°’(ë¶„)'] = result['ì¤‘ì•™ê°’_ë¶„'].round().astype('Int64')
            result['P90(ë¶„)'] = result['P90_ë¶„'].round().astype('Int64')
            result['ê³ ìœ ì—…ë¬´ìˆ˜'] = result['ê³ ìœ ì¥ë¹„ìˆ˜'].astype('Int64')
            result['ì¤‘ë³µì—…ë¬´ ìˆ˜'] = result['ì¬ë°œì¥ë¹„ìˆ˜'].astype('Int64')
            result['ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)'] = result['ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)'].round().astype('Int64')

            display_cols = ['êµ¬ë¶„', 'ê±´ìˆ˜', 'MTTR(ë¶„)', 'ì¤‘ì•™ê°’(ë¶„)', 'P90(ë¶„)', 'ê³ ìœ ì—…ë¬´ìˆ˜', 'ì¤‘ë³µì—…ë¬´ ìˆ˜', 'ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)']
            result_display = (
                result[display_cols]
                .sort_values(['MTTR(ë¶„)'], ascending=[True])
                .reset_index(drop=True)
            )

            fmt_all = {col: '{:.0f}' for col in result_display.columns if pd.api.types.is_numeric_dtype(result_display[col])}
            st.dataframe(result_display.style.format(fmt_all), use_container_width=True)

            result_display['MTTR_label'] = result_display['MTTR(ë¶„)'].astype('Int64').astype(str)
            # âœ… ì¶• ìƒí•œì„ ë™ì ìœ¼ë¡œ ë§ì¶° ë‘ ê·¸ë˜í”„ ë§‰ëŒ€ ë†’ì´ê°€ ë¹„ìŠ·í•˜ê²Œ ë³´ì´ë„ë¡ ì¡°ì •
            try:
                _mttr_max = float(result_display['MTTR(ë¶„)'].max())
                _dup_max = float(result_display['ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)'].max())
            except Exception:
                _mttr_max, _dup_max = 0.0, 0.0
            _mttr_ylim = max(10.0, _mttr_max * 1.1) if _mttr_max > 0 else 10.0
            _dup_ylim = min(100.0, max(10.0, _dup_max * 1.1)) if _dup_max > 0 else 10.0

            # âœ… êµ¬ë¶„ë³„ ìƒ‰ìƒ ê³ ì • ë§¤í•‘ (ë‘ ê·¸ë˜í”„ ê³µí†µ)
            cats = sorted(result_display['êµ¬ë¶„'].astype(str).unique())
            palette = px.colors.qualitative.Set2
            color_map = {c: palette[i % len(palette)] for i, c in enumerate(cats)}

            fig_mttr = px.bar(
                result_display,
                x='êµ¬ë¶„',
                y='MTTR(ë¶„)',
                color='êµ¬ë¶„',
                color_discrete_map=color_map,
                title='êµ¬ë¶„ë³„ MTTR(ë¶„)',
                labels={'MTTR(ë¶„)': 'MTTR(ë¶„)', 'êµ¬ë¶„': 'êµ¬ë¶„'},
                text='MTTR_label',
                custom_data=['MTTR_label']
            )
            fig_mttr.update_traces(textposition='outside', hovertemplate='êµ¬ë¶„: %{x}<br>MTTR(ë¶„): %{customdata[0]}<extra></extra>')
            fig_mttr.update_layout(legend_title_text='êµ¬ë¶„', margin=dict(t=60, b=0), height=420, bargap=0.2, yaxis_range=[0, _mttr_ylim])
            # (2ì—´ ë°°ì¹˜ë¡œ ì´ë™)
            pass

            # â–¼ êµ¬ë¶„ë³„ ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%) ê·¸ë˜í”„ â€” MTTR ê·¸ë˜í”„ ë°”ë¡œ ì•„ë˜ ë™ì¼ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            result_display['dup_label'] = result_display['ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)'].fillna(0).astype('Int64').astype(str)
            fig_dup_ratio = px.bar(
                result_display,
                x='êµ¬ë¶„',
                y='ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)',
                color='êµ¬ë¶„',
                color_discrete_map=color_map,
                title='êµ¬ë¶„ë³„ ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)',
                labels={'ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)': 'ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨(%)', 'êµ¬ë¶„': 'êµ¬ë¶„'},
                text='dup_label',
                custom_data=['dup_label']
            )
            fig_dup_ratio.update_traces(
                textposition='outside',
                hovertemplate='êµ¬ë¶„: %{x}<br>ì¤‘ë³µì—…ë¬´ ë¹„ìœ¨: %{customdata[0]}%<extra></extra>'
            )
            fig_dup_ratio.update_layout(legend_title_text='êµ¬ë¶„', yaxis_range=[0, _dup_ylim], margin=dict(t=60, b=0), height=420, bargap=0.2)
            cols_mttr = st.columns(2)
            with cols_mttr[0]:
                st.plotly_chart(fig_mttr, use_container_width=True)
            with cols_mttr[1]:
                st.plotly_chart(fig_dup_ratio, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ—“ï¸ ìš´ìš©íŒ€ ì¼ë³„ ì‘ì„±í˜„í™© (ì´ë™ì—…ë¬´ í¬í•¨)
        st.markdown("## ğŸ—“ï¸ ìš´ìš©íŒ€ ì¼ë³„ ì‘ì„±í˜„í™©")
        daily_count = df.groupby([pd.to_datetime(df['ì‹œì‘ì¼ì‹œ']).dt.date, df['íŒ€']]).size().unstack(fill_value=0).astype(int)
        daily_count.loc['í•©ê³„'] = daily_count.sum()
        st.dataframe(daily_count, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ“‰ íŒ€ ì£¼ì°¨ë³„ ê°€ë™ìœ¨ (ì´ë™ì—…ë¬´ í¬í•¨)
        st.markdown("## ğŸ“‰ íŒ€ ì£¼ì°¨ë³„ ê°€ë™ìœ¨")

        # âœ… 1ì¼ 1ì¸ë‹¹ ìƒí•œ ì œí•œ (600ë¶„)
        capped = df.groupby(['ì‘ì—…ì¼', 'ì‘ì—…ì', 'íŒ€', 'ì£¼ì°¨'])['ì‘ì—…ì‹œê°„(ë¶„)'].sum().clip(upper=600).reset_index()

        # âœ… íŒ€-ì£¼ì°¨ë³„ ì‘ì—…ì‹œê°„ ë° ê°€ë™ìœ¨ ê³„ì‚°
        df_team_time = capped.groupby(['íŒ€', 'ì£¼ì°¨'])['ì‘ì—…ì‹œê°„(ë¶„)'].sum().reset_index(name='íŒ€ì‘ì—…ì‹œê°„_ë¶„')
        unique_worker_count = capped.groupby(['íŒ€', 'ì£¼ì°¨'])['ì‘ì—…ì'].nunique().reset_index(name='ì‘ì—…ììˆ˜')
        df_weekly = df_team_time.merge(unique_worker_count, on=['íŒ€', 'ì£¼ì°¨'])
        df_weekly['ê¸°ì¤€ì‹œê°„'] = df_weekly['ì‘ì—…ììˆ˜'] * 2400
        df_weekly['ê°€ë™ìœ¨(%)'] = (df_weekly['íŒ€ì‘ì—…ì‹œê°„_ë¶„'] / df_weekly['ê¸°ì¤€ì‹œê°„']).clip(upper=1.0)

        team_count = df['íŒ€'].nunique()

        fig_util = px.bar(
            df_weekly,
            x='íŒ€',
            y='ê°€ë™ìœ¨(%)',
            color='ì£¼ì°¨',
            barmode='group',
            title='íŒ€ ì£¼ì°¨ë³„ ê°€ë™ìœ¨',
            labels={'ê°€ë™ìœ¨(%)': 'ê°€ë™ìœ¨', 'íŒ€': 'íŒ€'}
        )
        fig_util.update_layout(
            yaxis_tickformat='.0%',
            yaxis_range=[0, 1],
            legend_title_text='ì£¼ì°¨',
            legend=dict(orientation='h', y=-0.2, x=0.5, xanchor='center')
        )
        fig_util.add_shape(type="line", x0=-0.5, x1=team_count - 0.5, y0=0.68, y1=0.68, line=dict(color="red", width=2, dash="dot"))
        fig_util.add_annotation(x=team_count - 0.5, y=0.68, text="ê¸°ì¤€: 68%", showarrow=False, yshift=10, font=dict(color="red"))
        st.plotly_chart(fig_util, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ“Š ì¼ë³„ í‰ê·  ì‘ì—…ì‹œê°„ (ì´ë™ì—…ë¬´ í¬í•¨)
        st.markdown("## ğŸ“Š ì¼ë³„ í‰ê·  ì‘ì—…ì‹œê°„")

        daily_sum = capped.groupby(['ì‘ì—…ì¼', 'íŒ€'])['ì‘ì—…ì‹œê°„(ë¶„)'].sum().reset_index()
        daily_worker_count = capped.groupby(['ì‘ì—…ì¼', 'íŒ€'])['ì‘ì—…ì'].nunique().reset_index(name='ì‘ì—…ììˆ˜')
        daily_avg = daily_sum.merge(daily_worker_count, on=['ì‘ì—…ì¼', 'íŒ€'])
        daily_avg['í‰ê· ì‘ì—…ì‹œê°„(ì‹œê°„)'] = daily_avg['ì‘ì—…ì‹œê°„(ë¶„)'] / daily_avg['ì‘ì—…ììˆ˜'] / 60

        fig_daily = px.bar(
            daily_avg,
            x='íŒ€',
            y='í‰ê· ì‘ì—…ì‹œê°„(ì‹œê°„)',
            color='ì‘ì—…ì¼',
            barmode='group',
            title='ì¼ë³„ í‰ê·  ì‘ì—…ì‹œê°„',
            labels={'í‰ê· ì‘ì—…ì‹œê°„(ì‹œê°„)': 'í‰ê·  ì‘ì—…ì‹œê°„(ì‹œê°„)', 'ì‘ì—…ì¼': 'ë‚ ì§œ'}
        )
        fig_daily.update_layout(
            yaxis_range=[0, 10],
            legend=dict(
                orientation='h',
                y=-0.25,
                x=0.5,
                xanchor='center'
            )
        )
        fig_daily.add_shape(
            type="line",
            x0=-0.5,
            x1=len(daily_avg['íŒ€'].unique()) - 0.5,
            y0=6.2,
            y1=6.2,
            line=dict(color="red", width=2, dash="dot")
        )
        fig_daily.add_annotation(
            x=len(daily_avg['íŒ€'].unique()) - 0.5,
            y=6.2,
            text="ê¸°ì¤€: 6.2ì‹œê°„",
            showarrow=False,
            yshift=10,
            font=dict(color="red")
        )
        st.plotly_chart(fig_daily, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # â€ ğŸ‘·â€íŒ€ë³„ ìš´ìš©ì¡° í˜„í™©
        st.markdown("## ğŸ‘· íŒ€ë³„ ìš´ìš©ì¡° í˜„í™©")
        crew_base = df.groupby(['íŒ€', 'ì›ë³¸ì‘ì—…ì']).first().reset_index()
        crew_base['ì¡°êµ¬ì„±'] = crew_base['ì›ë³¸ì‘ì—…ì'].apply(lambda x: '2ì¸ 1ì¡°' if len(split_workers(x)) >= 2 else '1ì¸ 1ì¡°')
        crew_summary = crew_base.groupby(['íŒ€', 'ì¡°êµ¬ì„±']).size().unstack(fill_value=0)
        crew_summary_percent = crew_summary.div(crew_summary.sum(axis=1), axis=0).fillna(0).round(4) * 100

        st.dataframe(
            crew_summary_percent.T.style.format("{:.2f}%"),
            use_container_width=True
        )

        crew_summary_reset = crew_summary_percent.reset_index().melt(id_vars='íŒ€', var_name='ì¡°êµ¬ì„±', value_name='ë¹„ìœ¨')
        fig_crew = px.bar(
            crew_summary_reset,
            x='íŒ€',
            y='ë¹„ìœ¨',
            color='ì¡°êµ¬ì„±',
            color_discrete_map={'1ì¸ 1ì¡°': '#1f77b4', '2ì¸ 1ì¡°': '#ff7f0e'},
            barmode='group',
            title='íŒ€ë³„ ìš´ìš©ì¡° í˜„í™©',
            labels={'ë¹„ìœ¨': 'ë¹„ìœ¨(%)'}
        )
        fig_crew.update_layout(
            yaxis_range=[0, 100],
            yaxis_ticksuffix="%",
            legend=dict(orientation='h', y=-0.2, x=0.5, xanchor='center')
        )
        st.plotly_chart(fig_crew, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # âœ… ì—…ë¬´êµ¬ë¶„ë³„ ì¸ì›ì¡° í˜„í™©
        df_taskcrew = df.drop_duplicates(
            subset=['íŒ€', 'ì›ë³¸ì‘ì—…ì', 'ì‹œì‘ì¼ì‹œ', 'ì¢…ë£Œì¼ì‹œ', 'êµ¬ë¶„']
        ).copy()
        df_taskcrew['ì‘ì—…ìëª©ë¡'] = df_taskcrew['ì›ë³¸ì‘ì—…ì'].apply(split_workers)
        df_taskcrew['ì¡°êµ¬ì„±'] = df_taskcrew['ì‘ì—…ìëª©ë¡'].apply(
            lambda x: '2ì¸ 1ì¡°' if len(x) >= 2 else '1ì¸ 1ì¡°'
        )
        # ğŸ‘ ì—¬ê¸°ì„œëŠ” explode ë¶ˆí•„ìš” â€” ì‘ì—… 1ê±´ë‹¹ ì¡°êµ¬ì„± 1ê°œë§Œ ë°˜ì˜

        crew_task = df_taskcrew[['êµ¬ë¶„', 'ì¡°êµ¬ì„±']].copy()
        crew_task_grouped = crew_task.groupby(['êµ¬ë¶„', 'ì¡°êµ¬ì„±']).size().unstack(fill_value=0)
        crew_task_ratio = crew_task_grouped.div(crew_task_grouped.sum(axis=1), axis=0).fillna(0).round(4) * 100

        crew_task_reset = crew_task_ratio.reset_index().melt(id_vars='êµ¬ë¶„', var_name='ì¡°êµ¬ì„±', value_name='ë¹„ìœ¨')
        fig_crew_task = px.bar(
            crew_task_reset,
            x='êµ¬ë¶„',
            y='ë¹„ìœ¨',
            color='ì¡°êµ¬ì„±',
            color_discrete_map={'1ì¸ 1ì¡°': '#1f77b4', '2ì¸ 1ì¡°': '#ff7f0e'},
            barmode='group',
            title='ì—…ë¬´êµ¬ë¶„ë³„ ì¸ì›ì¡° í˜„í™©',
            labels={'ë¹„ìœ¨': 'ë¹„ìœ¨(%)'}
        )
        fig_crew_task.update_layout(
            yaxis_range=[0, 100],
            yaxis_ticksuffix="%",
            legend=dict(orientation='h', y=-0.2, x=0.5, xanchor='center')
        )
        st.plotly_chart(fig_crew_task, use_container_width=True)


if __name__ == '__main__':
    main()
